{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqwydhacIDd6",
        "outputId": "cb88614c-c77f-4d57-c806-42d9693eb73b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "N8gjT2Len6CW",
        "outputId": "cd47972d-8b88-4032-baea-76e049ce82ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy) (1.3.0)\n",
            "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/6.2 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m137.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.13.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "2644bd382ac44ef7a6c7f5d4b0e03e48",
              "pip_warning": {
                "packages": [
                  "sympy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -U sympy  # Update sympy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9MsMgohqzq5",
        "outputId": "e4f9fb8a-da20-4ab1-9ab7-20d09dfbaa4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Found existing installation: scipy 1.14.1\n",
            "Uninstalling scipy-1.14.1:\n",
            "  Successfully uninstalled scipy-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y numpy pandas scipy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CV32nCKjtAr4",
        "outputId": "a1b3a576-9fb5-4113-ae79-8a866ef274ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pandas==1.5.3\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy==1.9.3\n",
            "  Downloading scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.1 (from pandas==1.5.3)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas==1.5.3)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.1->pandas==1.5.3)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.4/33.4 MB\u001b[0m \u001b[31m143.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m228.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, six, numpy, scipy, python-dateutil, pandas\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.9.3 which is incompatible.\n",
            "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n",
            "cvxpy 1.6.5 requires scipy>=1.11.0, but you have scipy 1.9.3 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, but you have scipy 1.9.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.9.3 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.9.3 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.3 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5 pandas-1.5.3 python-dateutil-2.9.0.post0 pytz-2025.2 scipy-1.9.3 six-1.17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "numpy",
                  "six"
                ]
              },
              "id": "c854e530c2d14b59a2288cbe3b95c591"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install numpy==1.23.5 pandas==1.5.3 scipy==1.9.3 --no-cache-dir --force-reinstall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho1qqrd_tGqU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lasRurlcGl97",
        "outputId": "0fe81120-d99c-426d-c3d8-1fc89f27d6d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Dataset_major\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/Dataset_major"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFUsKlXJGujz",
        "outputId": "9228b62e-d9f8-47bf-8b4b-58d1290f2288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ECU-IoHT-Dataset.csv\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvz1JJ07KJkr",
        "outputId": "b814403f-debf-4873-dd32-aee0e29a2d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opacus\n",
            "  Downloading opacus-1.5.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.15 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.23.5)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.11/dist-packages (from opacus) (1.9.3)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->opacus)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->opacus) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n",
            "Downloading opacus-1.5.3-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, opacus\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opacus-1.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install opacus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ_o5JooG_3T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from opacus.accountants import RDPAccountant\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from opacus import PrivacyEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymtI6fdTHO1t"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"ECU-IoHT-Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDUP2v8iHXWE"
      },
      "outputs": [],
      "source": [
        "# Step 1: Data Cleaning\n",
        "df = df.dropna().drop_duplicates()  # Remove NaN and duplicates\n",
        "df.drop(columns=[\"Type of attack\"], inplace=True)  # Drop unnecessary column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le3qJ-55Hh4D",
        "outputId": "19a22762-6b02-4439-b406-6e64ff9dafe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in 'Source' before encoding:\n",
            " ['Alfa_97:cf:63' '6e:c7:ec:3c:f2:ba' '192.168.43.186' '192.168.43.1'\n",
            " 'Espressi_22:2d:c9' '192.168.43.200' '23.40.101.80' '13.32.73.101'\n",
            " '172.217.167.78' '142.250.67.3' '23.40.101.73' '13.32.73.124'\n",
            " '117.18.237.29' '142.250.66.196' '142.250.66.206' '172.217.167.66'\n",
            " '172.217.167.110' '216.58.196.133' '172.217.25.141' '172.217.167.99'\n",
            " '142.250.66.227' '216.58.203.110' '216.58.196.129' '52.50.150.86'\n",
            " '13.32.73.6' '172.217.167.74' '34.253.97.22' '216.58.199.78'\n",
            " '13.32.73.119' '34.196.191.3' '13.32.126.190' '13.32.73.42' '13.32.73.79'\n",
            " '104.22.52.65' '216.58.199.40' '104.16.85.20' '142.250.66.162'\n",
            " '157.240.8.23' '172.217.25.162' '172.217.25.34' '13.32.73.104'\n",
            " '104.22.53.65' '13.32.73.98' '142.250.66.174' '142.250.66.161'\n",
            " '13.238.187.36' '3.7.131.42' '157.240.8.7' '142.250.66.230'\n",
            " '103.43.90.20' '100.20.136.126' '104.18.7.124' '107.160.33.186'\n",
            " '67.202.110.24' '69.173.159.49' '52.9.210.145' '209.191.163.210'\n",
            " '35.244.159.8' '151.139.128.14' '157.240.8.35' '13.35.101.5'\n",
            " '142.250.67.14' '216.58.200.110' '192.124.249.23' '74.125.24.155'\n",
            " '172.217.194.157' '142.250.66.193' '96.7.134.29' '182.161.72.131'] \n",
            "\n",
            "Unique values in 'Source' after encoding:\n",
            " [67 64 45 44 68 46 55 10 36 28 54 13  7 23 24 34 33 49 39 37 25 53 48 60\n",
            " 15 35 58 51 12 57  9 14 16  4 50  2 20 30 40 41 11  5 17 21 19  8 56 32\n",
            " 26  1  0  3  6 62 63 61 47 59 29 31 18 27 52 43 65 38 22 66 42] \n",
            "\n",
            "Unique values in 'Destination' before encoding:\n",
            " ['Broadcast' 'Alfa_97:cf:63' '192.168.43.1' '192.168.43.186'\n",
            " '6e:c7:ec:3c:f2:ba' '192.168.43.200' 'Espressi_22:2d:c9' '52.208.217.22'\n",
            " '23.40.101.80' '13.32.73.101' '172.217.167.78' '142.250.67.3'\n",
            " '23.40.101.73' '13.32.73.124' '117.18.237.29' '142.250.66.196'\n",
            " '142.250.66.206' '172.217.167.66' '172.217.167.110' '216.58.196.133'\n",
            " '172.217.25.141' '172.217.167.99' '142.250.66.227' '216.58.203.110'\n",
            " '216.58.196.129' '52.50.150.86' '13.32.73.6' '172.217.167.74'\n",
            " '34.253.97.22' '216.58.199.78' '13.32.73.119' '34.196.191.3'\n",
            " '13.32.126.190' '13.32.73.42' '13.32.73.79' '104.22.52.65'\n",
            " '216.58.199.40' '104.16.85.20' '142.250.66.162' '157.240.8.23'\n",
            " '172.217.25.162' '172.217.25.34' '13.32.73.104' '104.22.53.65'\n",
            " '13.32.73.98' '142.250.66.174' '142.250.66.161' '13.238.187.36'\n",
            " '3.7.131.42' '142.250.66.230' '157.240.8.7' '103.43.90.20'\n",
            " '107.160.33.186' '104.18.7.124' '100.20.136.126' '67.202.110.24'\n",
            " '69.173.159.49' '52.9.210.145' '209.191.163.210' '35.244.159.8'\n",
            " '151.139.128.14' '157.240.8.35' '13.35.101.5' '142.250.67.14'\n",
            " '216.58.200.110' '192.124.249.23' '74.125.24.155' '172.217.194.157'\n",
            " '142.250.66.193' '96.7.134.29' '182.161.72.131'] \n",
            "\n",
            "Unique values in 'Destination' after encoding:\n",
            " [69 68 44 45 65 46 70 60 55 10 36 28 54 13  7 23 24 34 33 49 39 37 25 53\n",
            " 48 61 15 35 58 51 12 57  9 14 16  4 50  2 20 30 40 41 11  5 17 21 19  8\n",
            " 56 26 32  1  6  3  0 63 64 62 47 59 29 31 18 27 52 43 66 38 22 67 42] \n",
            "\n",
            "Unique values in 'Protocol' before encoding:\n",
            " ['ARP' 'DNS' 'TCP' 'LLC' 'ICMP' 'UDP' 'DHCP' 'TLSv1.1' 'HTTP' 'TLSv1.2'\n",
            " 'OCSP'] \n",
            "\n",
            "Unique values in 'Protocol' after encoding:\n",
            " [ 0  2  7  5  4 10  1  8  3  9  6] \n",
            "\n",
            "Unique values in 'Info' before encoding:\n",
            " ['Who has 192.168.43.1? Tell 192.168.43.186'\n",
            " '192.168.43.1 is at 6e:c7:ec:3c:f2:ba'\n",
            " 'Standard query 0x0c44 PTR 1.43.168.192.in-addr.arpa' ...\n",
            " '[TCP Dup ACK 111171#1] 3850  >  443 [ACK] Seq=684 Ack=518 Win=4048 Len=0'\n",
            " '3850  >  443 [RST, ACK] Seq=684 Ack=519 Win=5840 Len=0'\n",
            " '14550  >  443 [ACK] Seq=1 Ack=1 Win=5840 Len=0'] \n",
            "\n",
            "Unique values in 'Info' after encoding:\n",
            " [23250  1872 22388 ... 23574  6894  1338] \n",
            "\n",
            "Unique values in 'Type' before encoding:\n",
            " ['Attack' 'Normal'] \n",
            "\n",
            "Unique values in 'Type' after encoding:\n",
            " [0 1] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Encode Categorical Data\n",
        "categorical_cols = ['Source', 'Destination', 'Protocol', 'Info', 'Type']\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"Unique values in '{col}' before encoding:\\n\", df[col].unique(), \"\\n\")\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "    print(f\"Unique values in '{col}' after encoding:\\n\", df[col].unique(), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wa1XE22HnYG"
      },
      "outputs": [],
      "source": [
        "# Step 3: Split Features & Target\n",
        "X = df.drop(columns=['Type'])  # Features\n",
        "y = df['Type']  # Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD3121WCHuwo",
        "outputId": "10fd5d16-15ed-4df0-ae4c-681cd27dd162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after oversampling: Counter({0: 87754, 1: 87754})\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Balance Data using SMOTE\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "print(\"Class distribution after oversampling:\", Counter(y_resampled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BFX0c_dH0x_",
        "outputId": "14a6906d-0dba-4d6f-9d9f-1056f104e7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 5 rows after scaling:\n",
            "        No.      Time    Source  Destination  Protocol    Length      Info\n",
            "0 -1.549553 -1.975017  2.748075     3.318976 -2.807986 -0.378839  0.796384\n",
            "1 -1.549527 -1.975016  2.394368     3.187611 -2.807986 -0.378839 -2.503300\n",
            "2 -1.549501 -1.974949  2.748075     3.318976 -2.807986 -0.378839  0.796384\n",
            "3 -1.549475 -1.974948  0.154228     0.034844 -1.820478 -0.275503  0.663335\n",
            "4 -1.549448 -1.974877  2.394368     3.187611 -2.807986 -0.378839 -2.503300\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Standard Scaling\n",
        "scaler = StandardScaler()\n",
        "X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
        "X_resampled_scaled_df = pd.DataFrame(X_resampled_scaled, columns=X.columns)\n",
        "print(\"\\nFirst 5 rows after scaling:\")\n",
        "print(X_resampled_scaled_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIh4W1zZH3_t",
        "outputId": "de6ff098-5f81-4579-be6c-51bc6cefbf9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training set shape: (140406, 7) (140406,)\n",
            "Testing set shape: (35102, 7) (35102,)\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Train-Test Split (Stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_resampled_scaled,\n",
        "    y_resampled,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_resampled\n",
        ")\n",
        "print(\"\\nTraining set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Bx1XBdH71C",
        "outputId": "bc2ba48b-c02c-4e93-a6aa-73e1291343d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tensor shapes:\n",
            "X_train_tensor: torch.Size([140406, 7])\n",
            "X_test_tensor: torch.Size([35102, 7])\n",
            "y_train_tensor: torch.Size([140406])\n",
            "y_test_tensor: torch.Size([35102])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 7: Convert to PyTorch Tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)  # Using .values to ensure numpy array\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "print(\"\\nTensor shapes:\")\n",
        "print(\"X_train_tensor:\", X_train_tensor.shape)\n",
        "print(\"X_test_tensor:\", X_test_tensor.shape)\n",
        "print(\"y_train_tensor:\", y_train_tensor.shape)\n",
        "print(\"y_test_tensor:\", y_test_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xGN9VNXH_EA",
        "outputId": "c0635e85-3581-4306-be2e-79e86e4a59ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First batch from DataLoader:\n",
            "Batch X shape: torch.Size([32, 7])\n",
            "Batch y shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Create DataLoaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Verify DataLoader\n",
        "for batch_X, batch_y in train_loader:\n",
        "    print(\"\\nFirst batch from DataLoader:\")\n",
        "    print(\"Batch X shape:\", batch_X.shape)\n",
        "    print(\"Batch y shape:\", batch_y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apAA00xJJeGd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# 1. Define the CNN Model\n",
        "class FederatedCNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(FederatedCNN, self).__init__()\n",
        "        # 3 Convolutional Layers (64 → 32 → 16)\n",
        "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, padding=1)  # 1st layer: 64 nodes\n",
        "        self.conv2 = nn.Conv1d(64, 32, kernel_size=3, padding=1)  # 2nd layer: 32 nodes\n",
        "        self.conv3 = nn.Conv1d(32, 16, kernel_size=3, padding=1)  # 3rd layer: 16 nodes\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(16 * input_dim, 2)  # Output layer: 2 nodes (binary)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)  # Add channel dim (batch, 1, input_dim)\n",
        "        x = F.relu(self.conv1(x))  # ReLU for hidden layers\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return F.softmax(x, dim=1)  # Softmax for output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iB8GEcWLVmD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# 2. Training Functions\n",
        "def train_local_model(model, train_loader, epochs=5):\n",
        "    device = next(model.parameters()).device\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model.state_dict()\n",
        "\n",
        "def train_with_dp(model, train_loader, epochs=5, noise_scale=0.1):\n",
        "    \"\"\"Simplified DP training without Opacus\"\"\"\n",
        "    weights = train_local_model(model, train_loader, epochs)\n",
        "    # Add manual noise for DP\n",
        "    noisy_weights = {k: v + torch.randn_like(v) * noise_scale for k, v in weights.items()}\n",
        "    return noisy_weights, noise_scale  # Returning dummy epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71bHos6pLbkg"
      },
      "outputs": [],
      "source": [
        "# 3. Federated Utilities\n",
        "def aggregate_updates(global_model, client_weights, sample_counts):\n",
        "    global_weights = global_model.state_dict()\n",
        "    total_samples = sum(sample_counts)\n",
        "\n",
        "    for key in global_weights:\n",
        "        global_weights[key] = torch.stack(\n",
        "            [client_weights[i][key] * sample_counts[i] for i in range(len(client_weights))]\n",
        "        ).sum(dim=0) / total_samples\n",
        "\n",
        "    return global_weights\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "    all_labels, all_preds = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)\n",
        "            all_labels.extend(target.cpu().numpy())\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "\n",
        "    return (\n",
        "        accuracy_score(all_labels, all_preds),\n",
        "        precision_score(all_labels, all_preds, average='binary'),\n",
        "        recall_score(all_labels, all_preds, average='binary'),\n",
        "        f1_score(all_labels, all_preds, average='binary'),\n",
        "        confusion_matrix(all_labels, all_preds)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHR5hsrJLl94"
      },
      "outputs": [],
      "source": [
        "def run_federated_learning(train_loader, test_loader, num_clients=2, num_rounds=5, use_dp=False):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    input_dim = train_loader.dataset[0][0].shape[0]\n",
        "\n",
        "    # Initialize models\n",
        "    global_model = FederatedCNN(input_dim).to(device)\n",
        "    client_models = [FederatedCNN(input_dim).to(device) for _ in range(num_clients)]\n",
        "\n",
        "    # Split data among clients\n",
        "    client_loaders = []\n",
        "    client_size = len(train_loader.dataset) // num_clients\n",
        "    for i in range(num_clients):\n",
        "        indices = range(i * client_size,\n",
        "                        (i + 1) * client_size if i != num_clients - 1 else len(train_loader.dataset))\n",
        "        client_loaders.append(DataLoader(\n",
        "            Subset(train_loader.dataset, indices),\n",
        "            batch_size=32,\n",
        "            shuffle=True\n",
        "        ))\n",
        "\n",
        "    client_epsilons = []  # Track final epsilon values\n",
        "\n",
        "    # Training loop\n",
        "    for round_num in range(num_rounds):\n",
        "        print(f\"\\nRound {round_num + 1}/{num_rounds}\")\n",
        "        client_updates = []\n",
        "        sample_counts = []\n",
        "\n",
        "        for client_idx in range(num_clients):\n",
        "            print(f\"  Client {client_idx + 1}: Training...\", end=\"\")\n",
        "\n",
        "            if use_dp:\n",
        "                weights, epsilon = train_with_dp(client_models[client_idx], client_loaders[client_idx])\n",
        "                if round_num == num_rounds - 1:  # Save only final round's epsilon\n",
        "                    client_epsilons.append(epsilon)\n",
        "            else:\n",
        "                weights = train_local_model(client_models[client_idx], client_loaders[client_idx])\n",
        "\n",
        "\n",
        "            client_updates.append(weights)\n",
        "            sample_counts.append(len(client_loaders[client_idx].dataset))\n",
        "\n",
        "        # Aggregate updates\n",
        "        global_weights = aggregate_updates(global_model, client_updates, sample_counts)\n",
        "        global_model.load_state_dict(global_weights)\n",
        "\n",
        "        # Sync client models\n",
        "        for model in client_models:\n",
        "            model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "    # Final evaluation\n",
        "    accuracy, precision, recall, f1, cm = evaluate_model(global_model, test_loader)\n",
        "\n",
        "    # Display final metrics\n",
        "    print(f\"\\nFinal Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "    # Display final privacy budgets\n",
        "    if use_dp:\n",
        "        print(\"\\nFinal Privacy Budgets (ε) per client:\")\n",
        "        for idx, eps in enumerate(client_epsilons):\n",
        "            print(f\"Client {idx + 1}: ε = {eps:.4f}\")\n",
        "\n",
        "    # Visualize confusion matrix\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=[\"Predicted 0\", \"Predicted 1\"],\n",
        "                yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return global_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dN6gdngpLJY0",
        "outputId": "b8f72560-c8e0-4988-a5ce-5091b7f193bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Federated Learning...\n",
            "\n",
            "Round 1/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 2/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 3/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 4/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 5/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 6/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 7/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 8/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 9/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 10/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 11/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 12/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 13/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 14/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 15/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 16/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 17/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 18/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 19/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 20/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 21/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 22/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 23/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 24/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 25/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 26/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 27/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 28/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 29/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 30/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 31/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 32/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 33/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 34/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 35/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 36/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 37/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 38/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 39/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 40/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 41/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 42/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 43/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 44/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 45/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 46/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 47/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 48/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 49/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 50/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 51/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 52/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 53/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 54/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 55/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 56/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 57/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 58/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 59/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 60/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 61/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 62/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 63/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 64/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 65/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 66/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 67/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 68/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 69/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 70/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 71/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 72/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 73/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 74/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 75/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 76/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 77/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 78/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 79/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 80/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 81/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 82/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 83/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 84/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 85/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 86/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 87/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 88/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 89/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 90/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 91/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 92/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 93/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 94/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 95/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 96/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 97/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 98/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 99/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Round 100/100\n",
            "  Client 1: Training...  Client 2: Training...\n",
            "Final Metrics:\n",
            "Accuracy: 0.9602\n",
            "Precision: 0.9292, Recall: 0.9963, F1: 0.9616\n",
            "Confusion Matrix:\n",
            "[[16219  1332]\n",
            " [   65 17486]]\n",
            "\n",
            "Final Privacy Budgets (ε) per client:\n",
            "Client 1: ε = 0.1000\n",
            "Client 2: ε = 0.1000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 5. Execute Federated Learning\n",
        "print(\"Starting Federated Learning...\")\n",
        "global_model = run_federated_learning(\n",
        "    train_loader,  # From your preprocessing\n",
        "    test_loader,   # From your preprocessing\n",
        "    num_clients=2,\n",
        "    num_rounds=100,\n",
        "    use_dp=True     # Set to False to disable DP\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}